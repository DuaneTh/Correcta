---
phase: 04-ai-correction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/grading/openai-client.ts
  - lib/grading/schemas.ts
  - lib/grading/prompts.ts
  - lib/grading/rubric-generator.ts
  - lib/grading/grader.ts
  - prisma/schema.prisma
  - app/api/questions/[questionId]/rubric/route.ts
  - scripts/ai-grading-worker.ts
autonomous: true

must_haves:
  truths:
    - "OpenAI GPT-4 can be called with structured output schema"
    - "Rubric can be generated from question content and teacher guidelines"
    - "Teacher can view and edit generated rubric before grading"
    - "AI grading produces score, feedback, and rationale in consistent format"
  artifacts:
    - path: "lib/grading/openai-client.ts"
      provides: "OpenAI SDK singleton with gpt-4o model"
      exports: ["openai"]
    - path: "lib/grading/schemas.ts"
      provides: "Zod schemas for grading and rubric responses"
      exports: ["GradingResponseSchema", "RubricSchema"]
    - path: "lib/grading/grader.ts"
      provides: "Core grading function using OpenAI"
      exports: ["gradeAnswer"]
    - path: "lib/grading/rubric-generator.ts"
      provides: "Rubric generation from question content"
      exports: ["generateRubric"]
    - path: "prisma/schema.prisma"
      provides: "Question.generatedRubric JSON field"
      contains: "generatedRubric"
  key_links:
    - from: "scripts/ai-grading-worker.ts"
      to: "lib/grading/grader.ts"
      via: "import gradeAnswer"
      pattern: "import.*gradeAnswer.*from.*lib/grading/grader"
    - from: "lib/grading/grader.ts"
      to: "lib/grading/openai-client.ts"
      via: "OpenAI SDK"
      pattern: "openai\\.beta\\.chat\\.completions\\.parse"
---

<objective>
Establish OpenAI GPT-4 integration with structured outputs for AI grading, and implement rubric generation from question content.

Purpose: This is the foundation for all AI grading. Without the OpenAI client, Zod schemas, and grading logic, no AI correction can happen.

Output:
- OpenAI client configured with gpt-4o model
- Zod schemas for grading and rubric responses
- Rubric generation endpoint
- Updated worker with real GPT-4 calls (replacing stub)
- Database field for storing generated rubrics
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ai-correction/04-CONTEXT.md
@.planning/phases/04-ai-correction/04-RESEARCH.md

Key existing files:
@lib/queue.ts
@scripts/ai-grading-worker.ts
@lib/content.ts (segmentsToLatexString)
@prisma/schema.prisma
</context>

<tasks>

<task type="auto">
  <name>Task 1: OpenAI SDK setup and grading schemas</name>
  <files>
    lib/grading/openai-client.ts
    lib/grading/schemas.ts
    lib/grading/prompts.ts
  </files>
  <action>
Install OpenAI SDK and zod if not present: `npm install openai zod`

Create `lib/grading/openai-client.ts`:
- Export singleton OpenAI instance using `OPENAI_API_KEY` env var
- Add error handling for missing API key

Create `lib/grading/schemas.ts`:
- `GradingResponseSchema`: Zod schema with fields:
  - `score`: number (will be clamped to 0-maxPoints)
  - `feedback`: string (neutral academic tone, French)
  - `aiRationale`: string (internal reasoning, not shown to student)
- `RubricSchema`: Zod schema with fields:
  - `criteria`: array of { name: string, points: number, description: string }
  - `totalPoints`: number
- Export TypeScript types inferred from schemas

Create `lib/grading/prompts.ts`:
- `GRADING_SYSTEM_PROMPT`: French, neutral tone, explains score/feedback/rationale expectations
- `RUBRIC_GENERATION_PROMPT`: Instructions to generate grading criteria from question content
- Include instruction that AI can use $...$ for LaTeX in feedback
  </action>
  <verify>
`npm run build` passes without type errors.
Files exist: `lib/grading/openai-client.ts`, `lib/grading/schemas.ts`, `lib/grading/prompts.ts`.
  </verify>
  <done>
OpenAI SDK installed, client singleton exported, Zod schemas defined with TypeScript types, prompt templates ready.
  </done>
</task>

<task type="auto">
  <name>Task 2: Rubric generator and grading function</name>
  <files>
    lib/grading/rubric-generator.ts
    lib/grading/grader.ts
    prisma/schema.prisma
    app/api/questions/[questionId]/rubric/route.ts
  </files>
  <action>
Add `generatedRubric` field to Question model in `prisma/schema.prisma`:
```prisma
model Question {
  ...
  generatedRubric Json?    // AI-generated rubric for grading
  ...
}
```
Run `npx prisma db push` to apply schema change.

Create `lib/grading/rubric-generator.ts`:
- `generateRubric(params: { questionContent: string, correctionGuidelines: string | null, maxPoints: number })`:
  - Uses OpenAI with `zodResponseFormat(RubricSchema, "rubric")`
  - Calls gpt-4o with RUBRIC_GENERATION_PROMPT
  - Returns parsed RubricSchema object
  - Set temperature: 0.3 (some creativity for rubric generation)

Create `lib/grading/grader.ts`:
- `gradeAnswer(params: { question: string, rubric: string, studentAnswer: string, maxPoints: number })`:
  - Uses OpenAI with `zodResponseFormat(GradingResponseSchema, "grading")`
  - Calls gpt-4o with GRADING_SYSTEM_PROMPT
  - Temperature: 0 (deterministic grading)
  - max_tokens: 1000
  - Clamps returned score to 0-maxPoints range
  - Returns GradingResponse object

Create `app/api/questions/[questionId]/rubric/route.ts`:
- POST: Generate rubric for a question
  - Auth: Teacher only
  - CSRF: Required
  - Fetches question with segments and correctionGuidelines (from rubric.criteria)
  - Calls generateRubric()
  - Stores result in question.generatedRubric
  - Returns the generated rubric
- GET: Fetch existing rubric for a question
  - Auth: Teacher only
  - Returns question.generatedRubric or null
- PUT: Update/edit rubric
  - Auth: Teacher only
  - CSRF: Required
  - Validates rubric format
  - Updates question.generatedRubric
  </action>
  <verify>
`npx prisma db push` succeeds.
`npm run build` passes.
API routes exist and respond:
- `curl -X POST /api/questions/{id}/rubric` (with auth) generates rubric
- `curl -X GET /api/questions/{id}/rubric` returns rubric
  </verify>
  <done>
Rubric can be generated from question content, stored in DB, and retrieved/edited via API.
Grading function ready to be called by worker.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update AI grading worker with real GPT-4 calls</name>
  <files>
    scripts/ai-grading-worker.ts
    lib/content.ts
  </files>
  <action>
Update `scripts/ai-grading-worker.ts` to use real GPT-4 grading:

1. Import gradeAnswer from lib/grading/grader
2. Import segmentsToLatexString from lib/content

3. Modify the grade-answer job handler:
   a. Fetch answer with question, segments, and question.generatedRubric
   b. Convert answer segments to string using segmentsToLatexString()
   c. Convert question content to string using segmentsToLatexString()
   d. Get rubric from question.generatedRubric (parse JSON) or use correctionGuidelines as fallback
   e. Call gradeAnswer() with:
      - question: question content as string
      - rubric: JSON.stringify(generatedRubric) or correctionGuidelines
      - studentAnswer: answer content as string
      - maxPoints: sum of segment.maxPoints
   f. Upsert Grade with:
      - score: result.score (already clamped by grader)
      - feedback: result.feedback
      - aiRationale: result.aiRationale
      - gradedByUserId: null (marks as AI-graded)
      - isOverridden: false

4. Keep the existing check for human grades (skip if gradedByUserId !== null || isOverridden)

5. Add error handling:
   - Log OpenAI errors
   - Let BullMQ retry logic handle transient failures
   - On permanent failure, log error and continue (don't block queue)
  </action>
  <verify>
Worker can be started: `npx tsx scripts/ai-grading-worker.ts`
Queue a test job and verify:
- Real GPT-4 is called (check logs)
- Grade is created with AI-generated feedback
- Human-graded answers are not overwritten
  </verify>
  <done>
AI grading worker calls GPT-4 for real grading instead of returning stub 70% score.
Grades include personalized feedback and AI rationale.
  </done>
</task>

</tasks>

<verification>
1. OpenAI integration working:
   - OPENAI_API_KEY env var read correctly
   - Can make API calls to gpt-4o

2. Rubric generation:
   - POST /api/questions/{id}/rubric generates and stores rubric
   - GET /api/questions/{id}/rubric returns stored rubric

3. Worker grading:
   - Start worker, enqueue a grade-answer job
   - Verify Grade record created with feedback (not "Correction automatique (stub IA)")
   - Verify aiRationale is populated
   - Verify score is within 0-maxPoints range

4. Human grade protection:
   - Manually create a grade with gradedByUserId set
   - Enqueue AI grading for same answer
   - Verify human grade is not overwritten
</verification>

<success_criteria>
- OpenAI SDK integrated with structured output support
- Rubric generation API works end-to-end
- Worker produces real AI grades with personalized feedback
- Human grades are protected from AI overwrite
- All TypeScript types pass build
</success_criteria>

<output>
After completion, create `.planning/phases/04-ai-correction/04-01-SUMMARY.md`
</output>
